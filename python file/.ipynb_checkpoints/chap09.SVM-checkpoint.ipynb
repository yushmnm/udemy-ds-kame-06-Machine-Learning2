{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f29ace-ef93-4090-966d-bf9327789e07",
   "metadata": {},
   "source": [
    "## セクション９　SVM\n",
    "- 分類と回帰どっちでも使える\n",
    "- 精度が高いことで有名\n",
    "- 直近のデータからある程度余裕を持った方が未知のデータにも対応できる\n",
    "- あるデータがサポートとなり（サポートベクター）、そこからの距離（マージン）を最大化するように決定境界をひく\n",
    "- 距離を使うので、事前にSVMでは標準化をすることが望ましい\n",
    "\n",
    "### ソフトマージンとハードマージン\n",
    "- ハードマージン：誤分類を許容しない\n",
    "- ソフトマージン：誤分類を許容する（外れ値によって大きく結果が変わらない→ロバスト性が高い）  \n",
    "　境界の直近のデータがサポートベクターになるとは限らない\n",
    "\n",
    "### svmの損失関数\n",
    "- マージンを最大化にしつつ誤分類を減らすmin{1/M + C*Σ(ξi)}　：i番目のデータがマージンを犯した具合の残差の合計\n",
    "- パラメータ Cにより誤分類の許容を調整する\n",
    "- マージンMの逆数の最小化＝マージンMの最大化\n",
    "\n",
    "### 超平面（hyperplane）：n次の超平面の式（θ0x0+θ1x1+θ2x2+...+θnxn=0 θTX=0）\n",
    "- n次元空間内の平坦なn-1次元の集合\n",
    "- 線形分類器の決定境界は超平面になる \n",
    "\n",
    "### マージン\n",
    "- 決定境界である超平面からサポートベクターまでの距離\n",
    "- 先ほどの式の1/Mに当たる部分\n",
    "\n",
    "### 損失関数ξ側:ヒンジ損失を使う\n",
    "- 交差エントロピーを近似した損失で、近似により計算量が削減される（logの計算を省略）\n",
    "- １＜や<-1で損失するようにすることでマージンを考慮した損失となる（ある程度余裕を持って分類できていないと正解だとしても若干の損失が発生する）\n",
    "\n",
    "### カーネルトリック\n",
    "- svmを非線形分類可能のアルゴリズムとする\n",
    "- 特徴量空間を非線形変換することで非線形分離実現する\n",
    "- 写像する関数をφ（x）　＝ (φ1（x）　,φ2（x）　,...φr（x）　)とする\n",
    "  - xを（x、x^2）の二次元空間に写像する場合、φ（x）　＝ (φ1（x）　,φ2（x）) =(x,x^2)\n",
    "  - 写像すると、損失関数を解く上で必要な各データ間の内積の計算量が膨大になってしまう。これを防ぐのがカーネルトリック\n",
    "- カーネル関数K(xi,xj)に置き換えることで計算量を減らす"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4ac54-0854-4539-8756-c9ab243dd18e",
   "metadata": {},
   "source": [
    "### PythonでのSVM\n",
    "- sklearn.svm.SVC\n",
    "  - C:エラーの正則化項の係数(大きいと誤分類できなくなる)、Kernel：使用するカーネル（Linear,polynomial,rbf,sigmoid tanh）\n",
    "  - degree:'poly'のd（デフォは３）,gamma:'poly','rbf','sigmoid'の係数γ（'scale'(デフォ)、'auto'）\n",
    "  - .support_vectors_でサポートベクトルリストを取得する\n",
    "  - 回帰は、sklearn.svm.SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33362d1c-7932-4f5b-95e7-c9d126b50732",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionBoundaryDisplay\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fea7514-a77b-4b31-9909-807c5de35841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ準備\n",
    "df = sns.load_dataset('iris')\n",
    "y_col = 'species'\n",
    "X = df.drop(columns=[y_col])\n",
    "y = df[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# 標準化\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# PCA(サポート境界を可視化したいために２つの特徴量に次元を削減する)\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pc = pca.fit_transform(X_train)\n",
    "X_test_pc = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff75557-67e3-4838-a433-f69508069792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#学習\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_pc,y_train)\n",
    "\n",
    "#予測\n",
    "y_pred = model.predict(X_test_pc)\n",
    "\n",
    "#評価\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5774363f-7794-4377-8848-5d2eedc5806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.01808086, -2.16076222],\n",
       "       [-1.83691058,  0.22264198],\n",
       "       [ 0.68991796,  0.71639709],\n",
       "       [ 1.01841242,  0.75406273],\n",
       "       [ 1.14259734,  0.50582016],\n",
       "       [-0.59799672, -1.47307272],\n",
       "       [ 1.00108719, -1.69126085],\n",
       "       [ 0.21435381, -1.74582022],\n",
       "       [ 0.76807504,  0.17465618],\n",
       "       [ 0.58546256, -0.11934379],\n",
       "       [-0.65005847, -1.76724016],\n",
       "       [ 0.78292811,  0.42709078],\n",
       "       [ 1.05347893, -1.00878745],\n",
       "       [ 1.24654811,  0.22456375],\n",
       "       [ 0.8060938 , -0.04480644],\n",
       "       [ 0.67115053,  0.36047773],\n",
       "       [ 0.83577732, -1.44733591],\n",
       "       [ 1.36078095,  0.15396725],\n",
       "       [ 1.18175475, -0.56575389],\n",
       "       [ 0.9792362 , -0.36356179],\n",
       "       [ 0.21142607, -1.52270906],\n",
       "       [ 1.01399725, -0.74821922],\n",
       "       [ 0.86207563, -0.06985412],\n",
       "       [ 1.28474342,  0.5928925 ],\n",
       "       [ 1.326855  ,  0.92380604],\n",
       "       [ 1.08677516, -1.21143932],\n",
       "       [ 0.82552169, -0.03239705],\n",
       "       [ 1.52725209,  0.96532955],\n",
       "       [ 1.01399725, -0.74821922],\n",
       "       [ 1.31720646, -0.13584069]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　サポートベクトルの確認（後分類しているものも含めている）\n",
    "model.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce25066-ac6d-4ae3-bf9d-1badcf405df3",
   "metadata": {},
   "source": [
    "## 決定境界とサポートベクトルを可視化する\n",
    "- sklearn.inspection.DecisionBoundaryDisplay\n",
    "- .from_estimator(model,X)で描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20e8ff-0d85-49c0-8927-3e6fdcc3990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定境界描画\n",
    "DecisionBoundaryDisplay.from_estimator(model, \n",
    "                                       X_train_pc,\n",
    "                                       plot_method='contour',\n",
    "                                       cmap=plt.cm.Paired,\n",
    "                                       xlabel='first principal component',\n",
    "                                       ylabel='second principal component')\n",
    "\n",
    "# (PCA後の)学習データ描画\n",
    "for class_, color in zip(model.classes_, 'bry'):\n",
    "    idx = np.where(y_train == class_)\n",
    "    plt.scatter(X_train_pc[idx, 0],\n",
    "                X_train_pc[idx, 1],\n",
    "                c=color,\n",
    "                label=class_,\n",
    "                edgecolor='black',\n",
    "                s=20)\n",
    "\n",
    "# サポートベクトル描画\n",
    "plt.scatter(model.support_vectors_[:, 0],\n",
    "            model.support_vectors_[:, 1],\n",
    "            s=100,\n",
    "            facecolor='none',\n",
    "            linewidth=1,\n",
    "            edgecolor='black')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
